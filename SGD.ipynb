{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7600bb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c09afc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing function\n",
    "def preprocessing_data(df: pd.DataFrame):\n",
    "    data = df.copy()\n",
    "    # drop NaN values for some columns\n",
    "    data = data.dropna(subset=['education_level','major_discipline', 'experience', 'last_new_job'])\n",
    "    # Replace other NaN with Unknown value \n",
    "    data = data.replace(np.nan,'Unknown')\n",
    "    # relevent_experience replace with 0 and 1, 1 for having experience and 0 for no experience\n",
    "    data['relevent_experience'] = data['relevent_experience'].replace(['Has relevent experience','No relevent experience'],[1,0])\n",
    "\n",
    "    # manually assign ordinal numbers to education_level and company_size\n",
    "    # for graduate level I will give 1 and for master 2 and for phd 3. Graduate level can be equals to masters and phd but usually people with phd would not represent themselves as graduate. \n",
    "    # any graduate level certificate can be considered as graduate so I will assign a lower number to graduate than masters. \n",
    "    # for company_size unknown will get 0.\n",
    "    \n",
    "    data['education_level'] = data['education_level'].replace(['Graduate','Masters','Phd'],[1,2,3])\n",
    "    data['company_size'] = data['company_size'].replace(['Unknown','<10', '10/49','50-99', '100-500','500-999','1000-4999','5000-9999','10000+'] ,range(0,9))\n",
    "\n",
    "    # convert experience and last_new_job to numeric values\n",
    "    data['experience'] = data['experience'].str.replace('>','').str.replace('<','')\n",
    "    data['experience'] = pd.to_numeric(data['experience'])\n",
    "\n",
    "    data['last_new_job'] = data['last_new_job'].str.replace('>','')\n",
    "    data['last_new_job'] = data['last_new_job'].replace('never',0)\n",
    "    data['last_new_job'] = pd.to_numeric(data['last_new_job'])\n",
    "\n",
    "    data = pd.get_dummies(data, columns = ['company_type', 'enrolled_university', 'gender', 'major_discipline','city'])\n",
    "    \n",
    "    #Normalize data using MinMaxScaler function of sci-kit leaern\n",
    "    x = data.values #returns a numpy array\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    data_scaled = pd.DataFrame(x_scaled, columns = data.columns)\n",
    "    return(data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64318787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16007, 152)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data =  pd.read_csv(\"resources/aug_train.csv\")\n",
    "processed_data = preprocessing_data(raw_data)\n",
    "training_df = processed_data.copy()\n",
    "training_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03666a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>relevent_experience</th>\n",
       "      <th>education_level</th>\n",
       "      <th>experience</th>\n",
       "      <th>company_size</th>\n",
       "      <th>last_new_job</th>\n",
       "      <th>training_hours</th>\n",
       "      <th>target</th>\n",
       "      <th>company_type_Early Stage Startup</th>\n",
       "      <th>...</th>\n",
       "      <th>city_city_84</th>\n",
       "      <th>city_city_89</th>\n",
       "      <th>city_city_9</th>\n",
       "      <th>city_city_90</th>\n",
       "      <th>city_city_91</th>\n",
       "      <th>city_city_93</th>\n",
       "      <th>city_city_94</th>\n",
       "      <th>city_city_97</th>\n",
       "      <th>city_city_98</th>\n",
       "      <th>city_city_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.268051</td>\n",
       "      <td>0.942116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.104478</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.890497</td>\n",
       "      <td>0.654691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.137313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.346306</td>\n",
       "      <td>0.351297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.244776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.995836</td>\n",
       "      <td>0.680639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.152239</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019893</td>\n",
       "      <td>0.636727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.020896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 152 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   enrollee_id  city_development_index  relevent_experience  education_level  \\\n",
       "0     0.268051                0.942116                  1.0              0.0   \n",
       "1     0.890497                0.654691                  0.0              0.0   \n",
       "2     0.346306                0.351297                  0.0              0.0   \n",
       "3     0.995836                0.680639                  0.0              0.0   \n",
       "4     0.019893                0.636727                  1.0              0.5   \n",
       "\n",
       "   experience  company_size  last_new_job  training_hours  target  \\\n",
       "0    1.000000         0.000          0.25        0.104478     1.0   \n",
       "1    0.736842         0.375          1.00        0.137313     0.0   \n",
       "2    0.210526         0.000          0.00        0.244776     0.0   \n",
       "3    0.000000         0.000          0.00        0.152239     1.0   \n",
       "4    1.000000         0.375          1.00        0.020896     0.0   \n",
       "\n",
       "   company_type_Early Stage Startup  ...  city_city_84  city_city_89  \\\n",
       "0                               0.0  ...           0.0           0.0   \n",
       "1                               0.0  ...           0.0           0.0   \n",
       "2                               0.0  ...           0.0           0.0   \n",
       "3                               0.0  ...           0.0           0.0   \n",
       "4                               0.0  ...           0.0           0.0   \n",
       "\n",
       "   city_city_9  city_city_90  city_city_91  city_city_93  city_city_94  \\\n",
       "0          0.0           0.0           0.0           0.0           0.0   \n",
       "1          0.0           0.0           0.0           0.0           0.0   \n",
       "2          0.0           0.0           0.0           0.0           0.0   \n",
       "3          0.0           0.0           0.0           0.0           0.0   \n",
       "4          0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "   city_city_97  city_city_98  city_city_99  \n",
       "0           0.0           0.0           0.0  \n",
       "1           0.0           0.0           0.0  \n",
       "2           0.0           0.0           0.0  \n",
       "3           0.0           0.0           0.0  \n",
       "4           0.0           0.0           0.0  \n",
       "\n",
       "[5 rows x 152 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de013e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>relevent_experience</th>\n",
       "      <th>education_level</th>\n",
       "      <th>experience</th>\n",
       "      <th>company_size</th>\n",
       "      <th>last_new_job</th>\n",
       "      <th>training_hours</th>\n",
       "      <th>target</th>\n",
       "      <th>company_type_Early Stage Startup</th>\n",
       "      <th>...</th>\n",
       "      <th>city_city_84</th>\n",
       "      <th>city_city_89</th>\n",
       "      <th>city_city_9</th>\n",
       "      <th>city_city_90</th>\n",
       "      <th>city_city_91</th>\n",
       "      <th>city_city_93</th>\n",
       "      <th>city_city_94</th>\n",
       "      <th>city_city_97</th>\n",
       "      <th>city_city_98</th>\n",
       "      <th>city_city_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16007.000000</td>\n",
       "      <td>16007.000000</td>\n",
       "      <td>16007.000000</td>\n",
       "      <td>16007.000000</td>\n",
       "      <td>16007.000000</td>\n",
       "      <td>16007.000000</td>\n",
       "      <td>16007.000000</td>\n",
       "      <td>16007.000000</td>\n",
       "      <td>16007.000000</td>\n",
       "      <td>16007.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>16007.000000</td>\n",
       "      <td>16007.000000</td>\n",
       "      <td>16007.000000</td>\n",
       "      <td>16007.000000</td>\n",
       "      <td>16007.000000</td>\n",
       "      <td>16007.000000</td>\n",
       "      <td>16007.000000</td>\n",
       "      <td>16007.000000</td>\n",
       "      <td>16007.000000</td>\n",
       "      <td>16007.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.506736</td>\n",
       "      <td>0.762244</td>\n",
       "      <td>0.781158</td>\n",
       "      <td>0.158806</td>\n",
       "      <td>0.505772</td>\n",
       "      <td>0.400606</td>\n",
       "      <td>0.486693</td>\n",
       "      <td>0.191755</td>\n",
       "      <td>0.255451</td>\n",
       "      <td>0.032236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001312</td>\n",
       "      <td>0.003561</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.010308</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.001374</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.004248</td>\n",
       "      <td>0.004748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.289573</td>\n",
       "      <td>0.245885</td>\n",
       "      <td>0.413474</td>\n",
       "      <td>0.258531</td>\n",
       "      <td>0.338182</td>\n",
       "      <td>0.332819</td>\n",
       "      <td>0.339206</td>\n",
       "      <td>0.179169</td>\n",
       "      <td>0.436128</td>\n",
       "      <td>0.176632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036198</td>\n",
       "      <td>0.059569</td>\n",
       "      <td>0.027371</td>\n",
       "      <td>0.101007</td>\n",
       "      <td>0.045359</td>\n",
       "      <td>0.033516</td>\n",
       "      <td>0.037049</td>\n",
       "      <td>0.073103</td>\n",
       "      <td>0.065041</td>\n",
       "      <td>0.068744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.256861</td>\n",
       "      <td>0.587824</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.065672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.509947</td>\n",
       "      <td>0.922156</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.137313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.758464</td>\n",
       "      <td>0.942116</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.259701</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 152 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        enrollee_id  city_development_index  relevent_experience  \\\n",
       "count  16007.000000            16007.000000         16007.000000   \n",
       "mean       0.506736                0.762244             0.781158   \n",
       "std        0.289573                0.245885             0.413474   \n",
       "min        0.000000                0.000000             0.000000   \n",
       "25%        0.256861                0.587824             1.000000   \n",
       "50%        0.509947                0.922156             1.000000   \n",
       "75%        0.758464                0.942116             1.000000   \n",
       "max        1.000000                1.000000             1.000000   \n",
       "\n",
       "       education_level    experience  company_size  last_new_job  \\\n",
       "count     16007.000000  16007.000000  16007.000000  16007.000000   \n",
       "mean          0.158806      0.505772      0.400606      0.486693   \n",
       "std           0.258531      0.338182      0.332819      0.339206   \n",
       "min           0.000000      0.000000      0.000000      0.000000   \n",
       "25%           0.000000      0.210526      0.000000      0.250000   \n",
       "50%           0.000000      0.421053      0.375000      0.250000   \n",
       "75%           0.500000      0.842105      0.625000      1.000000   \n",
       "max           1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       training_hours        target  company_type_Early Stage Startup  ...  \\\n",
       "count    16007.000000  16007.000000                      16007.000000  ...   \n",
       "mean         0.191755      0.255451                          0.032236  ...   \n",
       "std          0.179169      0.436128                          0.176632  ...   \n",
       "min          0.000000      0.000000                          0.000000  ...   \n",
       "25%          0.065672      0.000000                          0.000000  ...   \n",
       "50%          0.137313      0.000000                          0.000000  ...   \n",
       "75%          0.259701      1.000000                          0.000000  ...   \n",
       "max          1.000000      1.000000                          1.000000  ...   \n",
       "\n",
       "       city_city_84  city_city_89   city_city_9  city_city_90  city_city_91  \\\n",
       "count  16007.000000  16007.000000  16007.000000  16007.000000  16007.000000   \n",
       "mean       0.001312      0.003561      0.000750      0.010308      0.002062   \n",
       "std        0.036198      0.059569      0.027371      0.101007      0.045359   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       city_city_93  city_city_94  city_city_97  city_city_98  city_city_99  \n",
       "count  16007.000000  16007.000000  16007.000000  16007.000000  16007.000000  \n",
       "mean       0.001125      0.001374      0.005373      0.004248      0.004748  \n",
       "std        0.033516      0.037049      0.073103      0.065041      0.068744  \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000  \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000  \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000  \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000  \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000  \n",
       "\n",
       "[8 rows x 152 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c422de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebd2b8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(training_df.drop('target',axis=1), \n",
    "                                                    training_df['target'], test_size=0.20, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbe49338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix , recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5da13b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usign SGD to model dataset\n",
    "SGD_model = SGDClassifier(max_iter=1000, tol=1e-3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec5c7990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "163ee0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD_predictions = SGD_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "997a99d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix is: \n",
      " [[2128  225]\n",
      " [ 519  330]]\n"
     ]
    }
   ],
   "source": [
    "print(\"confusion matrix is: \\n\", confusion_matrix(y_test,SGD_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3b59f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is:  0.7676452217364147 \n",
      "Precision is :  0.5945945945945946 \n",
      "Recall score is:  0.38869257950530034\n",
      "F1 Score:  0.47008547008547014\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score is: \" ,accuracy_score(SGD_predictions, y_test), '\\nPrecision is : ',precision_score(y_test,SGD_predictions),'\\nRecall score is: ' ,recall_score(y_test,SGD_predictions))\n",
    "print(\"F1 Score: \", f1_score(y_test, SGD_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b039b894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, SGD_predictions)).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64e53f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usign GridSearchCV to tune parameters\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43bfd987",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'loss': ['hinge', 'log', 'perceptron','squared_error','huber','epsilon_insensitive'], 'penalty': ['l1', 'l2','elasticnet'], 'alpha': [0.0001,0.1,100.0],'random_state': [1, None], 'max_iter': [100,1000,5000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0d1f923",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(SGDClassifier(),param_grid,refit=True,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "762a9f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "[CV 1/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=l1, random_state=1;, score=0.783 total time=   0.5s\n",
      "[CV 2/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=l1, random_state=1;, score=0.768 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=l1, random_state=1;, score=0.781 total time=   0.5s\n",
      "[CV 4/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=l1, random_state=1;, score=0.772 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=l1, random_state=1;, score=0.781 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=l1, random_state=None;, score=0.785 total time=   0.5s\n",
      "[CV 2/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=l1, random_state=None;, score=0.767 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=l1, random_state=None;, score=0.781 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=l1, random_state=None;, score=0.772 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=l1, random_state=None;, score=0.782 total time=   0.5s\n",
      "[CV 1/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=l2, random_state=1;, score=0.786 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=l2, random_state=1;, score=0.769 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=l2, random_state=1;, score=0.783 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=l2, random_state=1;, score=0.774 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=l2, random_state=1;, score=0.780 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=l2, random_state=None;, score=0.785 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=l2, random_state=None;, score=0.770 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=l2, random_state=None;, score=0.783 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=l2, random_state=None;, score=0.774 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=l2, random_state=None;, score=0.780 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=elasticnet, random_state=1;, score=0.786 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=elasticnet, random_state=1;, score=0.769 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=elasticnet, random_state=1;, score=0.782 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=elasticnet, random_state=1;, score=0.775 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=elasticnet, random_state=1;, score=0.780 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=elasticnet, random_state=None;, score=0.786 total time=   0.5s\n",
      "[CV 2/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=elasticnet, random_state=None;, score=0.769 total time=   0.6s\n",
      "[CV 3/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=elasticnet, random_state=None;, score=0.782 total time=   0.5s\n",
      "[CV 4/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=elasticnet, random_state=None;, score=0.774 total time=   0.5s\n",
      "[CV 5/5] END alpha=0.0001, loss=hinge, max_iter=100, penalty=elasticnet, random_state=None;, score=0.780 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, random_state=1;, score=0.783 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, random_state=1;, score=0.768 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, random_state=1;, score=0.781 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, random_state=1;, score=0.772 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, random_state=1;, score=0.781 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, random_state=None;, score=0.784 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, random_state=None;, score=0.767 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, random_state=None;, score=0.781 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, random_state=None;, score=0.772 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, random_state=None;, score=0.781 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, random_state=1;, score=0.786 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, random_state=1;, score=0.769 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, random_state=1;, score=0.783 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, random_state=1;, score=0.774 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, random_state=1;, score=0.780 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, random_state=None;, score=0.786 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, random_state=None;, score=0.770 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, random_state=None;, score=0.782 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, random_state=None;, score=0.774 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, random_state=None;, score=0.780 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.786 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.769 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.782 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.775 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.780 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.786 total time=   0.5s\n",
      "[CV 2/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.769 total time=   0.5s\n",
      "[CV 3/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.781 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.775 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.780 total time=   0.5s\n",
      "[CV 1/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=l1, random_state=1;, score=0.783 total time=   0.5s\n",
      "[CV 2/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=l1, random_state=1;, score=0.768 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=l1, random_state=1;, score=0.781 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=l1, random_state=1;, score=0.772 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=l1, random_state=1;, score=0.781 total time=   0.5s\n",
      "[CV 1/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=l1, random_state=None;, score=0.783 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=l1, random_state=None;, score=0.768 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=l1, random_state=None;, score=0.781 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=l1, random_state=None;, score=0.772 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=l1, random_state=None;, score=0.781 total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=l2, random_state=1;, score=0.786 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=l2, random_state=1;, score=0.769 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=l2, random_state=1;, score=0.783 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=l2, random_state=1;, score=0.774 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=l2, random_state=1;, score=0.780 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=l2, random_state=None;, score=0.786 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=l2, random_state=None;, score=0.770 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=l2, random_state=None;, score=0.782 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=l2, random_state=None;, score=0.774 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=l2, random_state=None;, score=0.780 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.786 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.769 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.782 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.775 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.780 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.786 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.769 total time=   0.5s\n",
      "[CV 3/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.781 total time=   0.5s\n",
      "[CV 4/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.774 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.0001, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.780 total time=   0.5s\n",
      "[CV 1/5] END alpha=0.0001, loss=log, max_iter=100, penalty=l1, random_state=1;, score=0.768 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=log, max_iter=100, penalty=l1, random_state=1;, score=0.764 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.0001, loss=log, max_iter=100, penalty=l1, random_state=1;, score=0.773 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=log, max_iter=100, penalty=l1, random_state=1;, score=0.772 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=log, max_iter=100, penalty=l1, random_state=1;, score=0.757 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.0001, loss=log, max_iter=100, penalty=l1, random_state=None;, score=0.790 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=log, max_iter=100, penalty=l1, random_state=None;, score=0.773 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.0001, loss=log, max_iter=100, penalty=l1, random_state=None;, score=0.777 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=log, max_iter=100, penalty=l1, random_state=None;, score=0.792 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=log, max_iter=100, penalty=l1, random_state=None;, score=0.762 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.0001, loss=log, max_iter=100, penalty=l2, random_state=1;, score=0.764 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.0001, loss=log, max_iter=100, penalty=l2, random_state=1;, score=0.763 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=log, max_iter=100, penalty=l2, random_state=1;, score=0.770 total time=   0.1s\n",
      "[CV 4/5] END alpha=0.0001, loss=log, max_iter=100, penalty=l2, random_state=1;, score=0.763 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=log, max_iter=100, penalty=l2, random_state=1;, score=0.760 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.0001, loss=log, max_iter=100, penalty=l2, random_state=None;, score=0.772 total time=   0.1s\n",
      "[CV 2/5] END alpha=0.0001, loss=log, max_iter=100, penalty=l2, random_state=None;, score=0.769 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.0001, loss=log, max_iter=100, penalty=l2, random_state=None;, score=0.767 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.0001, loss=log, max_iter=100, penalty=l2, random_state=None;, score=0.765 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=log, max_iter=100, penalty=l2, random_state=None;, score=0.769 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.0001, loss=log, max_iter=100, penalty=elasticnet, random_state=1;, score=0.772 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.0001, loss=log, max_iter=100, penalty=elasticnet, random_state=1;, score=0.765 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.0001, loss=log, max_iter=100, penalty=elasticnet, random_state=1;, score=0.770 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=log, max_iter=100, penalty=elasticnet, random_state=1;, score=0.762 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=log, max_iter=100, penalty=elasticnet, random_state=1;, score=0.758 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.0001, loss=log, max_iter=100, penalty=elasticnet, random_state=None;, score=0.795 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=log, max_iter=100, penalty=elasticnet, random_state=None;, score=0.780 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=log, max_iter=100, penalty=elasticnet, random_state=None;, score=0.774 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=log, max_iter=100, penalty=elasticnet, random_state=None;, score=0.761 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=log, max_iter=100, penalty=elasticnet, random_state=None;, score=0.765 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=l1, random_state=1;, score=0.768 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=l1, random_state=1;, score=0.764 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=l1, random_state=1;, score=0.773 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=l1, random_state=1;, score=0.772 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=l1, random_state=1;, score=0.757 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=l1, random_state=None;, score=0.766 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=l1, random_state=None;, score=0.770 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=l1, random_state=None;, score=0.774 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=l1, random_state=None;, score=0.775 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=l1, random_state=None;, score=0.775 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=l2, random_state=1;, score=0.764 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=l2, random_state=1;, score=0.763 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=l2, random_state=1;, score=0.770 total time=   0.1s\n",
      "[CV 4/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=l2, random_state=1;, score=0.763 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=l2, random_state=1;, score=0.760 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=l2, random_state=None;, score=0.781 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=l2, random_state=None;, score=0.776 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=l2, random_state=None;, score=0.770 total time=   0.1s\n",
      "[CV 4/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=l2, random_state=None;, score=0.776 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=l2, random_state=None;, score=0.765 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.772 total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.765 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.770 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.762 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.758 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.791 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.770 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.775 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.765 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=log, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.776 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=l1, random_state=1;, score=0.768 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=l1, random_state=1;, score=0.764 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=l1, random_state=1;, score=0.773 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=l1, random_state=1;, score=0.772 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=l1, random_state=1;, score=0.757 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=l1, random_state=None;, score=0.784 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=l1, random_state=None;, score=0.779 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=l1, random_state=None;, score=0.775 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=l1, random_state=None;, score=0.794 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=l1, random_state=None;, score=0.787 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=l2, random_state=1;, score=0.764 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=l2, random_state=1;, score=0.763 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=l2, random_state=1;, score=0.770 total time=   0.1s\n",
      "[CV 4/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=l2, random_state=1;, score=0.763 total time=   0.1s\n",
      "[CV 5/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=l2, random_state=1;, score=0.760 total time=   0.1s\n",
      "[CV 1/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=l2, random_state=None;, score=0.786 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=l2, random_state=None;, score=0.768 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=l2, random_state=None;, score=0.774 total time=   0.1s\n",
      "[CV 4/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=l2, random_state=None;, score=0.770 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=l2, random_state=None;, score=0.774 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.772 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.765 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.770 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.762 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.758 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.785 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.770 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.775 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.772 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=log, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.771 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=l1, random_state=1;, score=0.756 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=l1, random_state=1;, score=0.479 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=l1, random_state=1;, score=0.775 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=l1, random_state=1;, score=0.738 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=l1, random_state=1;, score=0.752 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=l1, random_state=None;, score=0.778 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=l1, random_state=None;, score=0.761 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=l1, random_state=None;, score=0.755 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=l1, random_state=None;, score=0.259 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=l1, random_state=None;, score=0.736 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=l2, random_state=1;, score=0.777 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=l2, random_state=1;, score=0.752 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=l2, random_state=1;, score=0.328 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=l2, random_state=1;, score=0.459 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=l2, random_state=1;, score=0.746 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=l2, random_state=None;, score=0.761 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=l2, random_state=None;, score=0.403 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=l2, random_state=None;, score=0.766 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=l2, random_state=None;, score=0.619 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=l2, random_state=None;, score=0.761 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=1;, score=0.759 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=1;, score=0.751 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=1;, score=0.755 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=1;, score=0.764 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=1;, score=0.763 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=None;, score=0.728 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=None;, score=0.655 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=None;, score=0.759 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=None;, score=0.714 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.0001, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=None;, score=0.745 total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, random_state=1;, score=0.756 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, random_state=1;, score=0.479 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, random_state=1;, score=0.775 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, random_state=1;, score=0.738 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, random_state=1;, score=0.752 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, random_state=None;, score=0.765 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, random_state=None;, score=0.768 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, random_state=None;, score=0.760 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, random_state=None;, score=0.749 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, random_state=None;, score=0.489 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, random_state=1;, score=0.777 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, random_state=1;, score=0.752 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, random_state=1;, score=0.328 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, random_state=1;, score=0.459 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, random_state=1;, score=0.746 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.1s\n",
      "[CV 2/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, random_state=None;, score=0.760 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, random_state=None;, score=0.738 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, random_state=None;, score=0.746 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, random_state=None;, score=0.748 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.759 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.751 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.755 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.764 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.763 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.770 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.758 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.430 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.761 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.264 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=l1, random_state=1;, score=0.756 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=l1, random_state=1;, score=0.479 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=l1, random_state=1;, score=0.775 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=l1, random_state=1;, score=0.738 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=l1, random_state=1;, score=0.752 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=l1, random_state=None;, score=0.775 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=l1, random_state=None;, score=0.626 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=l1, random_state=None;, score=0.315 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=l1, random_state=None;, score=0.768 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=l1, random_state=None;, score=0.765 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=l2, random_state=1;, score=0.777 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=l2, random_state=1;, score=0.752 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=l2, random_state=1;, score=0.328 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=l2, random_state=1;, score=0.459 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=l2, random_state=1;, score=0.746 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=l2, random_state=None;, score=0.764 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=l2, random_state=None;, score=0.618 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=l2, random_state=None;, score=0.702 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=l2, random_state=None;, score=0.768 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=l2, random_state=None;, score=0.742 total time=   0.1s\n",
      "[CV 1/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.759 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.751 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.755 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.764 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.763 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.783 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.623 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.730 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.718 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.745 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=l1, random_state=1;, score=0.543 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=l1, random_state=1;, score=0.464 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=l1, random_state=1;, score=0.453 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=l1, random_state=1;, score=0.507 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=l1, random_state=1;, score=0.507 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=l1, random_state=None;, score=0.504 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=l1, random_state=None;, score=0.526 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=l1, random_state=None;, score=0.600 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=l1, random_state=None;, score=0.501 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=l1, random_state=None;, score=0.510 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=l2, random_state=1;, score=0.497 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=l2, random_state=1;, score=0.488 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=l2, random_state=1;, score=0.508 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=l2, random_state=1;, score=0.438 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=l2, random_state=1;, score=0.444 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=l2, random_state=None;, score=0.574 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=l2, random_state=None;, score=0.699 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=l2, random_state=None;, score=0.576 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=l2, random_state=None;, score=0.484 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=l2, random_state=None;, score=0.529 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=1;, score=0.506 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=1;, score=0.519 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=1;, score=0.508 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=1;, score=0.439 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=1;, score=0.545 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=None;, score=0.565 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=None;, score=0.577 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=None;, score=0.386 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=None;, score=0.459 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.0001, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=None;, score=0.479 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=l1, random_state=1;, score=0.535 total time=   9.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=l1, random_state=1;, score=0.479 total time=   9.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=l1, random_state=1;, score=0.498 total time=   9.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=l1, random_state=1;, score=0.487 total time=   9.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=l1, random_state=1;, score=0.541 total time=   9.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=l1, random_state=None;, score=0.557 total time=   9.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=l1, random_state=None;, score=0.422 total time=   9.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=l1, random_state=None;, score=0.591 total time=   9.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=l1, random_state=None;, score=0.433 total time=  11.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=l1, random_state=None;, score=0.514 total time=  10.9s\n",
      "[CV 1/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=l2, random_state=1;, score=0.470 total time=   3.4s\n",
      "[CV 2/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=l2, random_state=1;, score=0.439 total time=   4.5s\n",
      "[CV 3/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=l2, random_state=1;, score=0.526 total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=l2, random_state=1;, score=0.463 total time=   4.8s\n",
      "[CV 5/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=l2, random_state=1;, score=0.475 total time=   1.8s\n",
      "[CV 1/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=l2, random_state=None;, score=0.441 total time=   3.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=l2, random_state=None;, score=0.507 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=l2, random_state=None;, score=0.509 total time=   5.0s\n",
      "[CV 4/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=l2, random_state=None;, score=0.407 total time=   4.7s\n",
      "[CV 5/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=l2, random_state=None;, score=0.427 total time=   4.8s\n",
      "[CV 1/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.549 total time=   5.9s\n",
      "[CV 2/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.540 total time=   5.2s\n",
      "[CV 3/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.524 total time=   4.4s\n",
      "[CV 4/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.445 total time=   9.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.525 total time=   3.9s\n",
      "[CV 1/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.614 total time=   4.6s\n",
      "[CV 2/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.533 total time=   9.3s\n",
      "[CV 3/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.451 total time=   6.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.463 total time=   8.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.471 total time=   7.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=l1, random_state=1;, score=0.545 total time=  51.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=l1, random_state=1;, score=0.496 total time=  47.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=l1, random_state=1;, score=0.464 total time=  47.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=l1, random_state=1;, score=0.716 total time=  47.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=l1, random_state=1;, score=0.560 total time=  54.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=l1, random_state=None;, score=0.506 total time=  57.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=l1, random_state=None;, score=0.503 total time=  58.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=l1, random_state=None;, score=0.584 total time=  55.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=l1, random_state=None;, score=0.459 total time=  55.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=l1, random_state=None;, score=0.389 total time=  55.8s\n",
      "[CV 1/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=l2, random_state=1;, score=0.470 total time=   3.6s\n",
      "[CV 2/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=l2, random_state=1;, score=0.439 total time=   5.1s\n",
      "[CV 3/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=l2, random_state=1;, score=0.526 total time=   3.9s\n",
      "[CV 4/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=l2, random_state=1;, score=0.453 total time=   8.9s\n",
      "[CV 5/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=l2, random_state=1;, score=0.475 total time=   2.2s\n",
      "[CV 1/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=l2, random_state=None;, score=0.474 total time=   3.2s\n",
      "[CV 2/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=l2, random_state=None;, score=0.421 total time=   3.7s\n",
      "[CV 3/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=l2, random_state=None;, score=0.449 total time=   7.2s\n",
      "[CV 4/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=l2, random_state=None;, score=0.459 total time=   8.7s\n",
      "[CV 5/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=l2, random_state=None;, score=0.570 total time=   4.1s\n",
      "[CV 1/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.549 total time=   7.1s\n",
      "[CV 2/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.540 total time=   5.8s\n",
      "[CV 3/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.524 total time=   4.4s\n",
      "[CV 4/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.445 total time=  10.2s\n",
      "[CV 5/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.525 total time=   3.7s\n",
      "[CV 1/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.471 total time=   8.2s\n",
      "[CV 2/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.453 total time=   4.9s\n",
      "[CV 3/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.418 total time=   5.6s\n",
      "[CV 4/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.387 total time=   4.1s\n",
      "[CV 5/5] END alpha=0.0001, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.447 total time=  11.0s\n",
      "[CV 1/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=l1, random_state=1;, score=0.783 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=l1, random_state=1;, score=0.770 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=l1, random_state=1;, score=0.777 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=l1, random_state=1;, score=0.772 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=l1, random_state=1;, score=0.781 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=l1, random_state=None;, score=0.783 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=l1, random_state=None;, score=0.770 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=l1, random_state=None;, score=0.777 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=l1, random_state=None;, score=0.772 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=l1, random_state=None;, score=0.781 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=l2, random_state=1;, score=0.783 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=l2, random_state=1;, score=0.768 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=l2, random_state=1;, score=0.778 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=l2, random_state=1;, score=0.772 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=l2, random_state=1;, score=0.782 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=l2, random_state=None;, score=0.783 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=l2, random_state=None;, score=0.768 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=l2, random_state=None;, score=0.777 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=l2, random_state=None;, score=0.772 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=l2, random_state=None;, score=0.783 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=elasticnet, random_state=1;, score=0.783 total time=   0.1s\n",
      "[CV 2/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=elasticnet, random_state=1;, score=0.772 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=elasticnet, random_state=1;, score=0.777 total time=   0.1s\n",
      "[CV 4/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=elasticnet, random_state=1;, score=0.772 total time=   0.1s\n",
      "[CV 5/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=elasticnet, random_state=1;, score=0.781 total time=   0.1s\n",
      "[CV 1/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=elasticnet, random_state=None;, score=0.783 total time=   0.1s\n",
      "[CV 2/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=elasticnet, random_state=None;, score=0.772 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=elasticnet, random_state=None;, score=0.777 total time=   0.1s\n",
      "[CV 4/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=elasticnet, random_state=None;, score=0.772 total time=   0.1s\n",
      "[CV 5/5] END alpha=0.0001, loss=huber, max_iter=100, penalty=elasticnet, random_state=None;, score=0.781 total time=   0.1s\n",
      "[CV 1/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=l1, random_state=1;, score=0.783 total time=   0.1s\n",
      "[CV 2/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=l1, random_state=1;, score=0.770 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=l1, random_state=1;, score=0.777 total time=   0.1s\n",
      "[CV 4/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=l1, random_state=1;, score=0.772 total time=   0.1s\n",
      "[CV 5/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=l1, random_state=1;, score=0.781 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=l1, random_state=None;, score=0.783 total time=   0.1s\n",
      "[CV 2/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=l1, random_state=None;, score=0.770 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=l1, random_state=None;, score=0.777 total time=   0.1s\n",
      "[CV 4/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=l1, random_state=None;, score=0.772 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=l1, random_state=None;, score=0.781 total time=   0.1s\n",
      "[CV 1/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=l2, random_state=1;, score=0.783 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=l2, random_state=1;, score=0.768 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=l2, random_state=1;, score=0.778 total time=   0.1s\n",
      "[CV 4/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=l2, random_state=1;, score=0.772 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=l2, random_state=1;, score=0.782 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=l2, random_state=None;, score=0.783 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=l2, random_state=None;, score=0.767 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=l2, random_state=None;, score=0.777 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=l2, random_state=None;, score=0.772 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=l2, random_state=None;, score=0.782 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.783 total time=   0.1s\n",
      "[CV 2/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.772 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.777 total time=   0.1s\n",
      "[CV 4/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.772 total time=   0.1s\n",
      "[CV 5/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.781 total time=   0.1s\n",
      "[CV 1/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.783 total time=   0.1s\n",
      "[CV 2/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.772 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.777 total time=   0.1s\n",
      "[CV 4/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.772 total time=   0.1s\n",
      "[CV 5/5] END alpha=0.0001, loss=huber, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.781 total time=   0.1s\n",
      "[CV 1/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=l1, random_state=1;, score=0.783 total time=   0.1s\n",
      "[CV 2/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=l1, random_state=1;, score=0.770 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=l1, random_state=1;, score=0.777 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=l1, random_state=1;, score=0.772 total time=   0.1s\n",
      "[CV 5/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=l1, random_state=1;, score=0.781 total time=   0.1s\n",
      "[CV 1/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=l1, random_state=None;, score=0.783 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=l1, random_state=None;, score=0.770 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=l1, random_state=None;, score=0.777 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=l1, random_state=None;, score=0.772 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=l1, random_state=None;, score=0.781 total time=   0.1s\n",
      "[CV 1/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=l2, random_state=1;, score=0.783 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=l2, random_state=1;, score=0.768 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=l2, random_state=1;, score=0.778 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=l2, random_state=1;, score=0.772 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=l2, random_state=1;, score=0.782 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=l2, random_state=None;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=l2, random_state=None;, score=0.767 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=l2, random_state=None;, score=0.777 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=l2, random_state=None;, score=0.772 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=l2, random_state=None;, score=0.781 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.783 total time=   0.1s\n",
      "[CV 2/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.772 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.777 total time=   0.1s\n",
      "[CV 4/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.772 total time=   0.1s\n",
      "[CV 5/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.781 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.783 total time=   0.1s\n",
      "[CV 2/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.772 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.777 total time=   0.1s\n",
      "[CV 4/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.772 total time=   0.1s\n",
      "[CV 5/5] END alpha=0.0001, loss=huber, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.781 total time=   0.1s\n",
      "[CV 1/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=1;, score=0.783 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=1;, score=0.768 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=1;, score=0.781 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=1;, score=0.772 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=1;, score=0.782 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=None;, score=0.783 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=None;, score=0.768 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=None;, score=0.781 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=None;, score=0.772 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=None;, score=0.781 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=1;, score=0.786 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=1;, score=0.769 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=1;, score=0.782 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=1;, score=0.774 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=1;, score=0.779 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=None;, score=0.786 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=None;, score=0.770 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=None;, score=0.781 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=None;, score=0.774 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=None;, score=0.779 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=1;, score=0.786 total time=   0.5s\n",
      "[CV 2/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=1;, score=0.769 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=1;, score=0.781 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=1;, score=0.774 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=1;, score=0.779 total time=   0.5s\n",
      "[CV 1/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=None;, score=0.786 total time=   0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=None;, score=0.769 total time=   0.6s\n",
      "[CV 3/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=None;, score=0.781 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=None;, score=0.774 total time=   0.6s\n",
      "[CV 5/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=None;, score=0.779 total time=   0.5s\n",
      "[CV 1/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=1;, score=0.783 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=1;, score=0.768 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=1;, score=0.781 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=1;, score=0.772 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=1;, score=0.782 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=None;, score=0.783 total time=   0.5s\n",
      "[CV 2/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=None;, score=0.767 total time=   0.5s\n",
      "[CV 3/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=None;, score=0.781 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=None;, score=0.772 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=None;, score=0.781 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=1;, score=0.786 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=1;, score=0.769 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=1;, score=0.782 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=1;, score=0.774 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=1;, score=0.779 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=None;, score=0.786 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=None;, score=0.769 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=None;, score=0.781 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=None;, score=0.774 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=None;, score=0.780 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.786 total time=   0.5s\n",
      "[CV 2/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.769 total time=   0.5s\n",
      "[CV 3/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.781 total time=   0.5s\n",
      "[CV 4/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.774 total time=   0.5s\n",
      "[CV 5/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.779 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.786 total time=   0.5s\n",
      "[CV 2/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.769 total time=   0.5s\n",
      "[CV 3/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.781 total time=   0.5s\n",
      "[CV 4/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.774 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.779 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=1;, score=0.783 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=1;, score=0.768 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=1;, score=0.781 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=1;, score=0.772 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=1;, score=0.782 total time=   0.5s\n",
      "[CV 1/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=None;, score=0.783 total time=   0.5s\n",
      "[CV 2/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=None;, score=0.768 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=None;, score=0.781 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=None;, score=0.772 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=None;, score=0.782 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=1;, score=0.786 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=1;, score=0.769 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=1;, score=0.782 total time=   0.3s\n",
      "[CV 4/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=1;, score=0.774 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=1;, score=0.779 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=None;, score=0.786 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=None;, score=0.769 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=None;, score=0.781 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=None;, score=0.774 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=None;, score=0.780 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.786 total time=   0.5s\n",
      "[CV 2/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.769 total time=   0.5s\n",
      "[CV 3/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.781 total time=   0.5s\n",
      "[CV 4/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.774 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.779 total time=   0.5s\n",
      "[CV 1/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.786 total time=   0.5s\n",
      "[CV 2/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.769 total time=   0.5s\n",
      "[CV 3/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.781 total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.774 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.0001, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.779 total time=   0.5s\n",
      "[CV 1/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=hinge, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=log, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=log, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.1, loss=log, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=log, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=log, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=log, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=log, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=log, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=log, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=log, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=log, max_iter=100, penalty=l2, random_state=1;, score=0.749 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=log, max_iter=100, penalty=l2, random_state=1;, score=0.751 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=log, max_iter=100, penalty=l2, random_state=1;, score=0.749 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=log, max_iter=100, penalty=l2, random_state=1;, score=0.749 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=log, max_iter=100, penalty=l2, random_state=1;, score=0.749 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=log, max_iter=100, penalty=l2, random_state=None;, score=0.749 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=log, max_iter=100, penalty=l2, random_state=None;, score=0.751 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=log, max_iter=100, penalty=l2, random_state=None;, score=0.749 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=log, max_iter=100, penalty=l2, random_state=None;, score=0.748 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=log, max_iter=100, penalty=l2, random_state=None;, score=0.749 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=log, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.1s\n",
      "[CV 2/5] END alpha=0.1, loss=log, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=log, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=log, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.1s\n",
      "[CV 5/5] END alpha=0.1, loss=log, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=log, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.1s\n",
      "[CV 2/5] END alpha=0.1, loss=log, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.1, loss=log, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=log, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=log, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.1s\n",
      "[CV 1/5] END alpha=0.1, loss=log, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=log, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=log, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=log, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=log, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=log, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=log, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=log, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=log, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=log, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=log, max_iter=1000, penalty=l2, random_state=1;, score=0.749 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=log, max_iter=1000, penalty=l2, random_state=1;, score=0.751 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=log, max_iter=1000, penalty=l2, random_state=1;, score=0.749 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=log, max_iter=1000, penalty=l2, random_state=1;, score=0.749 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=log, max_iter=1000, penalty=l2, random_state=1;, score=0.749 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=log, max_iter=1000, penalty=l2, random_state=None;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=log, max_iter=1000, penalty=l2, random_state=None;, score=0.751 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=log, max_iter=1000, penalty=l2, random_state=None;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=log, max_iter=1000, penalty=l2, random_state=None;, score=0.749 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=log, max_iter=1000, penalty=l2, random_state=None;, score=0.749 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=log, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=log, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=log, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=log, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=log, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.1, loss=log, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=log, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=log, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=log, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=log, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=log, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=log, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=log, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=log, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=log, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=log, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=log, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=log, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=log, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=log, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=log, max_iter=5000, penalty=l2, random_state=1;, score=0.749 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=log, max_iter=5000, penalty=l2, random_state=1;, score=0.751 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=log, max_iter=5000, penalty=l2, random_state=1;, score=0.749 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=log, max_iter=5000, penalty=l2, random_state=1;, score=0.749 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=log, max_iter=5000, penalty=l2, random_state=1;, score=0.749 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=log, max_iter=5000, penalty=l2, random_state=None;, score=0.749 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=log, max_iter=5000, penalty=l2, random_state=None;, score=0.751 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=log, max_iter=5000, penalty=l2, random_state=None;, score=0.749 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=log, max_iter=5000, penalty=l2, random_state=None;, score=0.749 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=log, max_iter=5000, penalty=l2, random_state=None;, score=0.749 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=log, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=log, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=log, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=log, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=log, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=log, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=log, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=log, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=log, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=log, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=l1, random_state=1;, score=0.253 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=l1, random_state=1;, score=0.253 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=l1, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=l1, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=l2, random_state=1;, score=0.608 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=l2, random_state=1;, score=0.562 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=l2, random_state=1;, score=0.772 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=l2, random_state=1;, score=0.585 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=l2, random_state=1;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=l2, random_state=None;, score=0.760 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=l2, random_state=None;, score=0.756 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=l2, random_state=None;, score=0.767 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=l2, random_state=None;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=l2, random_state=None;, score=0.742 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=1;, score=0.253 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=1;, score=0.253 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=None;, score=0.721 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=None;, score=0.724 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=None;, score=0.720 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=None;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=None;, score=0.748 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l1, random_state=1;, score=0.253 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l1, random_state=1;, score=0.253 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l1, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l2, random_state=1;, score=0.608 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l2, random_state=1;, score=0.562 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l2, random_state=1;, score=0.772 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l2, random_state=1;, score=0.585 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l2, random_state=1;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l2, random_state=None;, score=0.768 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l2, random_state=None;, score=0.751 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l2, random_state=None;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l2, random_state=None;, score=0.734 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=l2, random_state=None;, score=0.744 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.253 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.253 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.765 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.253 total time=   0.1s\n",
      "[CV 4/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.733 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=l1, random_state=1;, score=0.253 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=l1, random_state=1;, score=0.253 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=l1, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=l2, random_state=1;, score=0.608 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=l2, random_state=1;, score=0.562 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=l2, random_state=1;, score=0.772 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=l2, random_state=1;, score=0.585 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=l2, random_state=1;, score=0.300 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=l2, random_state=None;, score=0.779 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=l2, random_state=None;, score=0.740 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=l2, random_state=None;, score=0.760 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=l2, random_state=None;, score=0.761 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=l2, random_state=None;, score=0.583 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.253 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.253 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.780 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.706 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.772 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.781 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=l1, random_state=1;, score=0.503 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=l1, random_state=1;, score=0.485 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=l1, random_state=1;, score=0.494 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=l1, random_state=1;, score=0.493 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=l1, random_state=1;, score=0.466 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=l1, random_state=None;, score=0.480 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=l1, random_state=None;, score=0.435 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=l1, random_state=None;, score=0.423 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=l1, random_state=None;, score=0.519 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=l1, random_state=None;, score=0.480 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=l2, random_state=1;, score=0.506 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=l2, random_state=1;, score=0.518 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=l2, random_state=1;, score=0.495 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=l2, random_state=1;, score=0.486 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=l2, random_state=1;, score=0.496 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=l2, random_state=None;, score=0.491 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=l2, random_state=None;, score=0.519 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=l2, random_state=None;, score=0.505 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=l2, random_state=None;, score=0.486 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=l2, random_state=None;, score=0.504 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=1;, score=0.510 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=1;, score=0.520 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=1;, score=0.494 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=1;, score=0.485 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=1;, score=0.491 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=None;, score=0.487 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=None;, score=0.521 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=None;, score=0.504 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=None;, score=0.484 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.1, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=None;, score=0.510 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=l1, random_state=1;, score=0.468 total time=  10.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=l1, random_state=1;, score=0.486 total time=  11.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=l1, random_state=1;, score=0.471 total time=  10.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=l1, random_state=1;, score=0.510 total time=  10.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=l1, random_state=1;, score=0.478 total time=   9.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=l1, random_state=None;, score=0.552 total time=  10.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=l1, random_state=None;, score=0.564 total time=  10.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=l1, random_state=None;, score=0.635 total time=  10.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=l1, random_state=None;, score=0.467 total time=  10.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=l1, random_state=None;, score=0.542 total time=  10.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=l2, random_state=1;, score=0.509 total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=l2, random_state=1;, score=0.520 total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=l2, random_state=1;, score=0.495 total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=l2, random_state=1;, score=0.487 total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=l2, random_state=1;, score=0.496 total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=l2, random_state=None;, score=0.491 total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=l2, random_state=None;, score=0.480 total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=l2, random_state=None;, score=0.496 total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=l2, random_state=None;, score=0.486 total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=l2, random_state=None;, score=0.504 total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.512 total time=  10.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.522 total time=  10.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.494 total time=   9.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.485 total time=   9.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.490 total time=   9.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.513 total time=  10.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.522 total time=  10.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.506 total time=   9.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.517 total time=  10.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.1, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.490 total time=   9.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=l1, random_state=1;, score=0.447 total time=  47.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=l1, random_state=1;, score=0.494 total time=  48.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=l1, random_state=1;, score=0.444 total time=  49.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=l1, random_state=1;, score=0.511 total time=  55.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=l1, random_state=1;, score=0.487 total time=  45.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=l1, random_state=None;, score=0.594 total time=  46.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=l1, random_state=None;, score=0.371 total time=  46.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=l1, random_state=None;, score=0.439 total time=  47.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=l1, random_state=None;, score=0.529 total time=  47.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=l1, random_state=None;, score=0.540 total time=  47.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=l2, random_state=1;, score=0.509 total time=  24.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=l2, random_state=1;, score=0.520 total time=  25.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=l2, random_state=1;, score=0.495 total time=  24.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=l2, random_state=1;, score=0.487 total time=  24.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=l2, random_state=1;, score=0.496 total time=  28.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=l2, random_state=None;, score=0.491 total time=  28.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=l2, random_state=None;, score=0.480 total time=  29.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=l2, random_state=None;, score=0.505 total time=  29.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=l2, random_state=None;, score=0.487 total time=  29.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=l2, random_state=None;, score=0.496 total time=  29.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.513 total time=  58.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.522 total time=  58.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.494 total time=  54.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.485 total time=  55.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.490 total time=  46.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.487 total time=  47.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.477 total time=  46.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.494 total time=  46.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.485 total time=  47.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sabat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.1, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.490 total time=  47.3s\n",
      "[CV 1/5] END alpha=0.1, loss=huber, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=huber, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=huber, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=huber, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=huber, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=huber, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=huber, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=huber, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=huber, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=huber, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=huber, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=huber, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=huber, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=huber, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=huber, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=huber, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=huber, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=huber, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=huber, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=huber, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=huber, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=huber, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=huber, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=huber, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.1s\n",
      "[CV 5/5] END alpha=0.1, loss=huber, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.1s\n",
      "[CV 1/5] END alpha=0.1, loss=huber, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.1s\n",
      "[CV 2/5] END alpha=0.1, loss=huber, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.1, loss=huber, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.1s\n",
      "[CV 4/5] END alpha=0.1, loss=huber, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=huber, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=huber, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=huber, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.1s\n",
      "[CV 4/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.1s\n",
      "[CV 5/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.1s\n",
      "[CV 1/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=l1, random_state=None;, score=0.253 total time=   0.1s\n",
      "[CV 4/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=l2, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.1s\n",
      "[CV 3/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.1s\n",
      "[CV 1/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.1s\n",
      "[CV 5/5] END alpha=100.0, loss=hinge, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.1s\n",
      "[CV 3/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.1s\n",
      "[CV 1/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.1s\n",
      "[CV 2/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=l1, random_state=None;, score=0.253 total time=   0.1s\n",
      "[CV 3/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.1s\n",
      "[CV 4/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.1s\n",
      "[CV 4/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=hinge, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.253 total time=   0.1s\n",
      "[CV 1/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.1s\n",
      "[CV 2/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.1s\n",
      "[CV 1/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=l1, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.1s\n",
      "[CV 2/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=hinge, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=log, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=log, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=log, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=log, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=100.0, loss=log, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=log, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=log, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=log, max_iter=100, penalty=l1, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=log, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=log, max_iter=100, penalty=l1, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=log, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=log, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=log, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=log, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=log, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=log, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=log, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=log, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=log, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=log, max_iter=100, penalty=l2, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=log, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=log, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=log, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=log, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=log, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=log, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=log, max_iter=100, penalty=elasticnet, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=log, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=log, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=log, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=log, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=log, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=log, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=log, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=log, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=log, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=log, max_iter=1000, penalty=l1, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=log, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=log, max_iter=1000, penalty=l1, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=log, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=log, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=log, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=log, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=log, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=log, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=log, max_iter=1000, penalty=l2, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=log, max_iter=1000, penalty=l2, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=log, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=log, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=log, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=log, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=log, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=log, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=log, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=log, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=log, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=log, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=log, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=log, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=log, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=log, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=log, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=log, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=log, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=log, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=log, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=log, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=log, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=log, max_iter=5000, penalty=l1, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=log, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=log, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=log, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=log, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=log, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=log, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=log, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=log, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=100.0, loss=log, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=log, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=log, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=log, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=log, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=log, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=log, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=log, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=log, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=log, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=log, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=log, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=log, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=l1, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=perceptron, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=l1, random_state=None;, score=0.253 total time=   0.1s\n",
      "[CV 4/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=l1, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=l2, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=perceptron, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=l2, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.253 total time=   0.1s\n",
      "[CV 2/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.253 total time=   0.1s\n",
      "[CV 3/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=perceptron, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=l1, random_state=None;, score=0.253 total time=   0.1s\n",
      "[CV 5/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=l2, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=None;, score=0.253 total time=   0.1s\n",
      "[CV 3/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=None;, score=0.253 total time=   0.1s\n",
      "[CV 4/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=squared_error, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=l1, random_state=None;, score=0.253 total time=   0.1s\n",
      "[CV 4/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=l2, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.253 total time=   0.1s\n",
      "[CV 3/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=squared_error, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=squared_error, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=huber, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=huber, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=huber, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=huber, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=huber, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=huber, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=huber, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=huber, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=huber, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=huber, max_iter=100, penalty=l1, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=huber, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=huber, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=100.0, loss=huber, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=huber, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=huber, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=huber, max_iter=100, penalty=l2, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=huber, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=huber, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=huber, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=huber, max_iter=100, penalty=l2, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=huber, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=huber, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=huber, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=huber, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=huber, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=huber, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=huber, max_iter=100, penalty=elasticnet, random_state=None;, score=0.253 total time=   0.1s\n",
      "[CV 3/5] END alpha=100.0, loss=huber, max_iter=100, penalty=elasticnet, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=huber, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=huber, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=l1, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=l1, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=l2, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=huber, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=l2, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=l2, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=huber, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.1s\n",
      "[CV 5/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=None;, score=0.253 total time=   0.1s\n",
      "[CV 2/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=100, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.1s\n",
      "[CV 2/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=1000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.1s\n",
      "[CV 2/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.1s\n",
      "[CV 3/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=l1, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=l2, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=1;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.253 total time=   0.0s\n",
      "[CV 2/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 3/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END alpha=100.0, loss=epsilon_insensitive, max_iter=5000, penalty=elasticnet, random_state=None;, score=0.747 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SGDClassifier(),\n",
       "             param_grid={'alpha': [0.0001, 0.1, 100.0],\n",
       "                         'loss': ['hinge', 'log', 'perceptron', 'squared_error',\n",
       "                                  'huber', 'epsilon_insensitive'],\n",
       "                         'max_iter': [100, 1000, 5000],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                         'random_state': [1, None]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "659e81ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best combination is : SGDClassifier(loss='log', max_iter=5000, penalty='l1')\n"
     ]
    }
   ],
   "source": [
    "print(\"the best combination is :\" ,grid.best_estimator_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8acb017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3850f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAEGCAYAAAAT05LOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAe/klEQVR4nO3deZQV1bn+8e/DPAgyKzIENKhBoqg4xWhwSCTe/OLwixEyqIkG9TrlxuRGM2huvOS6YszgHKJGvYkDzppBo0ajSZzACSe0ESINCDIoyNDQ3e/941TjAZruU02fPqdPPZ+19upTu3ZV7UOvftm7dtXeigjMzLKmQ6krYGZWCg5+ZpZJDn5mlkkOfmaWSQ5+ZpZJnUpdgXwD+nWMEcM6l7oalsIbL/UodRUshbWsYl3UaGvOccQhPWPpsrqCys54qebBiJiwNdcrlrIKfiOGdeaZB4eVuhqWwhE7jC11FSyFp+ORrT7HkmV1PP3g0ILKdh48e8BWX7BIyir4mVl7ENRFfakrsdUc/MwslQDqaf8vRzj4mVlq9bjlZ2YZEwTr3e01s6wJoK4Cur1+zs/MUqsnCkpNkTRM0qOSXpP0iqRzkvx+kh6S9Gbys2/eMedLqpI0S9IRefl7S5qZ7LtMUrOP8zj4mVkqAdRFFJSaUQucGxEfA/YHzpA0GjgPeCQiRgGPJNsk+yYCuwETgKskdUzOdTUwGRiVpGafLXTwM7PU6gtMTYmIhRHxXPJ5JfAaMAQ4CrgxKXYjcHTy+Sjg1oioiYg5QBWwr6TBQO+IeDJyc/TdlHfMFvmen5mlEkSae34DJE3P254aEVM3LSRpBLAn8DSwXUQshFyAlDQoKTYEeCrvsOokb33yedP8Jjn4mVkqEbC+8PGOJRExrqkCkrYB7gS+GRErmrhd19iOaCK/SQ5+ZpaSqGs03rTgTFJncoHv9xFxV5K9SNLgpNU3GFic5FcD+e+/DgUWJPlDG8lvku/5mVkqAdRHYakpyYjsdcBrEfHzvF33AScmn08E7s3Lnyipq6SR5AY2nkm6yCsl7Z+c84S8Y7bILT8zS62VWn4HAl8FZkp6Icn7HnAxME3SycDbwHEAEfGKpGnAq+RGis+IiIbpZU4HbgC6A39OUpMc/MwsldxDzlsf/CLi7zR+vw7gsC0cMwWY0kj+dGBMmus7+JlZKgGsj/Z/x8zBz8xSCURdBQwXOPiZWWr10TqjvaXk4GdmqbTWPb9Sc/Azs5REne/5mVnW5GZydvAzs4yJEOuiY/MFy5yDn5mlVu97fmaWNbkBD3d7zSxzPOBhZhnkAQ8zy6w6P+RsZlkTiPXR/kNH+/8GZtamPOBhZpkUyN1eM8smD3iYWeZE4EddzCx7cgMefr3NzDLIAx5mljmBPJmpmWVTJbT82v83MLM2lVu3t0NBqTmSrpe0WNLLeXm3SXohSXMblrWUNELSmrx91+Qds7ekmZKqJF2WrN/bJLf8zCwlteY09jcAVwA3NWRExPEbriRdCryfV352RIxt5DxXA5OBp4A/ARNoZu1eBz8zSyW3dGXrjPZGxOOSRjS2L2m9fRE4tKlzSBoM9I6IJ5Ptm4CjaSb4udtrZqlEKE23d4Ck6XlpcopLHQQsiog38/JGSnpe0t8kHZTkDQGq88pUJ3lNcsvPzFJL8ZDzkogY18LLTAJuydteCAyPiKWS9gbukbQbNNoHj+ZO7uBnZqnk5vMr7qMukjoBxwJ7b7huRA1Qk3yeIWk2sDO5lt7QvMOHAguau4a7vWaWUm4m50LSVjgceD0iNnRnJQ2U1DH5vCMwCngrIhYCKyXtn9wnPAG4t7kLOPiZWSq5R11UUGqOpFuAJ4FdJFVLOjnZNZGNu7wABwMvSXoRuAM4LSKWJftOB64FqoDZNDPYAe72mllKrflub0RM2kL+SY3k3QncuYXy04Exaa7t4GdmqXlKKzPLnNyUVn6318wyyBMbmFnm5GZ1cbfXzDIm93qbg18mLZ7fmUvOGc7yxZ1Rh+DIryzlmFOWsGJ5R35y2ggWVXdhu6Hr+P6v59KrTx216+EX3x5O1czu1NWKw49bxsSzFgPw5kvd+dk3h1OztgP7HrqC0y+aT/PzUdjWGLjDOr7zq7fpO6iWqIc//a4/91w3kO9dM5ehO9UA0LN3HatWdOTfP70Lu4xdzTmXzANyrxL876Xb888Hti3hNyg1t/yaJWkC8CugI3BtRFxczOu1lY6dgskXLGDU7mtY/UEHzpywM3sdvJKHbuvHnp9cyfFnLea2ywdx2xWDOOUHC3n8/j6srxG//uss1q4Wk8d/jPFHv8f2w9Zx2XlDOeen8/jY3qv5wVd2ZPqjvdjn0JWl/ooVra5WTP3xDlTN7EH3nnVc8cAbPPd4L35y2ogNZSZfsIBVK3N/4HNndePMCTtTXyf6DVrP1Q+/wVMP9aa+Lrv/SxX7DY+2ULTwnTyJfSXwWWA0MEnS6GJdry31366WUbuvAaDHNvUM+2gNSxZ25skHt+XwL+aeuTz8i8t4MmkdSLB2dQfqamHd2g506lJPj23qWLqoE6tXdmT0uNVIcPgXlmW8RdE2li3uTNXMHgCsWdWReVXdGDB4fV6J4ODPv8ej9/QFoGZNhw2BrnPXeqLZt0YrW8NobyGpnBWz5bcvUBURbwFIuhU4Cni1iNdsc+/M68Lsl7uz616rWb6kM/23qwVyAfK9pbl/3oM+9x5PPrgtk8aOYe0acdp/LaB33zreeLH7Rn90A3ZYz5J3Opfke2TVdkPXsdOYNbz+XI8NeWP2W8XydzuxYE7XDXm77LmKc38+j0FD1/PTs4ZnutUHuNvbjCHAvLztamC/TQslU9xMBhg+pH3dglyzqgMXnTKC0348n5696rdYbtbzPenQMbj5+Zf54P1OnHv0R9nzoJWNtiCy/SfVtrr1qOOH187lmgt2YPUHH76xcMjR7/HYPX02Kjvr+Z5MPmRXhn10Ld/51ds8+2gv1te0/wDQEpWyhkcxf3sFTTMTEVMjYlxEjBvYv/0sh1e7Hi46ZQSHHrucTx6Zm2i274D1LF2UC+BLF3WiT/9cK/DRu/sw7pCVdOoMfQbUMnqfVbzxYg8GDF7PkoUftvSWLOhM/+3Xb34xa3UdOwU/vHYuf72rL//4c58N+R06Bgce+T5/u69Po8fNq+rG2tUdGLHL2rapaBkKoDY6FJTKWTFrVw0My9suaJqZ9iACfn7ucIaNquH/n/ruhvz9P7OCh6f1A+Dhaf044IhcUBw4ZD0v/H0bInL3/l5/rifDPrqW/tvV0mObel6b0YMIePiOD4+xYgq+dek85r3ZjbumDtxoz14HrWReVVeWLOyyIW+7YTV06Jj7f3vQkHUM3amGRdVdyLLWWsOjlIrZz3wWGCVpJDCf3CwNXyri9drMK8/05JE7+jHyY2s4/fBdAPja+Qs4/sxFTDltBA/c2p9BQ3KPugB8/mtLuPQ/hjP5kF0gxGeOX8qOo3Mth7MunsfPvjmcdWs7MO6QFR7pbQO77buKw49bzluvduOqh2YB8Nv/Gcyzf+3Np47avMs7Zt9VHH/mHGprRX29uPx7Q1mxrH3domlVBc7YUu4URRy6knQk8Etyj7pcHxFTmio/bo9u8cyDw5oqYmXmiB3GlroKlsLT8QgrYtlWRa6+uw6KQ6//QkFl7zrw6hlbMZNzURX1v6+I+BO5lZTMrIJUQssvw213M2uJhslM2zsHPzNLJRC19eU9mFEIBz8zS60SXm9z8DOzdMLdXjPLIN/zM7PMqoTg1/7vWppZmwpEXX2HglJzJF0vabGkl/PyfiRpvqQXknRk3r7zJVVJmiXpiLz8vSXNTPZdlqzf2yQHPzNLrR4VlApwAzChkfxfRMTYJP0JIJkSbyKwW3LMVQ2LmANXk5sgZVSSGjvnRhz8zCyViNZbtDwiHgeWNVsw5yjg1oioiYg55BYo31fSYKB3RDwZuVfWbgKObu5kDn5mllqECkrAAEnT89LkAi9xpqSXkm5x3ySvsWnyhiSpupH8JnnAw8xSSjWxwZIWvNt7NXARuYHli4BLga+z5WnyCpo+b1MOfmaWWhRxtDciFjV8lvQb4A/J5pamyatOPm+a3yR3e80slQioq1dBqSWSe3gNjgEaRoLvAyZK6ppMlTcKeCYiFgIrJe2fjPKeANzb3HXc8jOz1Frr9TZJtwDjyd0brAYuBMZLGkuu6zoXOBUgIl6RNI3cOkC1wBkRUZec6nRyI8fdgT8nqUkOfmaWStB63d6ImNRI9nVNlJ8CbDYvaERMB8akubaDn5mlVBkzOTv4mVlqlbB2sYOfmaVWzNHetuLgZ2ap5EZ72/+DIg5+Zpaau71mlknu9ppZ5gRy8DOzbKqAXq+Dn5mlFBAtfHWtnDj4mVlq7vaaWSZV9GivpMtpomsfEWcXpUZmVtZa893eUmqq5Te9zWphZu1HAJUc/CLixvxtST0jYlXxq2Rm5a4Sur3NvqMi6QBJrwKvJdt7SLqq6DUzszIlor6wVM4KeUHvl8ARwFKAiHgROLiIdTKzchcFpjJW0GhvRMzbZA3gui2VNbMKF5U/4NFgnqRPACGpC3A2SRfYzDKqzFt1hSik23sacAa5dTDnA2OTbTPLLBWYylezLb+IWAJ8uQ3qYmbtRX2pK7D1Chnt3VHS/ZLelbRY0r2SdmyLyplZGWp4zq+QVMYK6fbeDEwDBgM7ALcDtxSzUmZW3iIKS82RdH3SqHo5L+8SSa9LeknS3ZL6JPkjJK2R9EKSrsk7Zm9JMyVVSbpMm4zQNqaQ4KeI+N+IqE3S76iI251m1mKt96jLDcCETfIeAsZExO7AG8D5eftmR8TYJJ2Wl381MJncQuajGjnnZrYY/CT1k9QPeFTSeUnU/Yik/wT+WMi3MrMK1Urd3oh4HFi2Sd5fIqI22XwKGNrUOSQNBnpHxJMREcBNwNHNXbupAY8Z5GJ3wzc4Nb9+wEXNndzMKpMK7/sNkJQ/T8DUiJia4lJfB27L2x4p6XlgBfCDiHiC3JMo1XllqpO8JjX1bu/IFBU0s6wIQeGvri2JiHEtuYyk7wO1wO+TrIXA8IhYKmlv4B5Ju9H4MzXNhueC3vCQNAYYDXTbcOaImwo51swqUJHv+ks6EfgccFjSlSUiaoCa5PMMSbOBncm19PK7xkOBBc1do9ngJ+lCYDy54Pcn4LPA38n1q80si4oY/CRNAL4LfCoiVuflDwSWRURd8rjdKOCtiFgmaaWk/YGngROAy5u7TiGjvV8ADgPeiYivAXsAXVN/IzOrHK002ivpFuBJYBdJ1ZJOBq4AegEPbfJIy8HAS5JeBO4ATouIhsGS04FrgSpgNvDn5q5dSLd3TUTUS6qV1BtYDPghZ7OsasXJTCNiUiPZ122h7J3AnVvYNx0Yk+bahQS/6clDhr8hNwL8AfBMmouYWWVJMdpbtgp5t/ffk4/XSHqA3PM0LxW3WmZW1io5+Enaq6l9EfFccapkZuWu0lt+lzaxL4BDW7kuvPlab/5t72bfSrEy0mmkx77aE1V3aZ0TlfmkBYVo6iHnQ9qyImbWTrSDKeoL4UXLzSw9Bz8zyyJVwGSmDn5mll4FtPwKmclZkr4i6YJke7ikfYtfNTMrR4rCUzkr5PW2q4ADgIYnsVcCVxatRmZW/ipgGvtCur37RcReyRxaRMTyZAlLM8uqMm/VFaKQ4LdeUkeSr5vMrFABtzvNrKXKvUtbiEKC32XA3cAgSVPIzfLyg6LWyszKV2RktDcifi9pBrlprQQcHRGvFb1mZla+stDykzQcWA3cn58XEW8Xs2JmVsayEPzIrdTWsJBRN2AkMAvYrYj1MrMylol7fhHx8fztZLaXU7dQ3MysXUj9hkdEPCdpn2JUxszaiSy0/CR9K2+zA7AX8G7RamRm5S0ro73kFhJpUEvuHmCj8+ibWUZUessvebh5m4j4ThvVx8zKnKiMAY8tvtsrqVNE1JHr5pqZfaj1lq68XtJiSS/n5fWT9JCkN5OfffP2nS+pStIsSUfk5e8taWay7zJJzb5Y3NTEBg0rtL0g6T5JX5V0bENq/muZWUVq3VldbgA2XbviPOCRiBgFPJJsI2k0MJHcY3YTgKuS3inA1cBkcguZj2rknJspZFaXfsBScmt2fA74f8lPM8uq+gJTMyLicWDZJtlHATcmn28Ejs7LvzUiaiJiDrkFyveVNJjcqpJPRkQAN+Uds0VN3fMblIz0vsyHDzlvqHNzJzazypXint8ASdPztqdGxNRmjtkuIhYCRMRCSYOS/CHAU3nlqpO89cnnTfOb1FTw6whsw8ZBr4GDn1mWFR4BlkTEuFa66pZiUYtiVFPBb2FE/LjQWplZRhR/9bZFkgYnrb7BwOIkvxoYllduKLAgyR/aSH6TmrrnV97TsJpZyRR5Gvv7gBOTzycC9+blT5TUVdJIcgMbzyRd5JWS9k9GeU/IO2aLmmr5HdbiqptZZWullp+kW4Dx5O4NVgMXAhcD0ySdDLwNHAcQEa9Imga8Su6FizOSx/EATic3ctwd+HOSmtTUouWbjsCYmQGt93pbREzawq5GG18RMQWY0kj+dGBMmmt76UozS6f49/zahIOfmaUiKmNAwMHPzNJzy8/MsqgSJjZw8DOz9Bz8zCxzMjSZqZnZxtzyM7Ms8j0/M8smBz8zyyK3/Mwse4KCJiotdw5+ZpZKpSxg5OBnZuk5+JlZFinaf/Rz8DOzdDyri5llle/5mVkm+fU2M8smt/zMLHO2bnGisuHgZ2bpOfiZWdZUykPOTa3ba2bWKNVHQanJc0i7SHohL62Q9E1JP5I0Py//yLxjzpdUJWmWpCO25ju45Wdm6bTSc34RMQsYCyCpIzAfuBv4GvCLiPhZfnlJo4GJwG7ADsDDknbOW7s3Fbf8WkmHDsFlv/8nF/7yOQC26b2O/75yOlPvfoL/vnI62/Rav1H5gduv4Y4nHubYr84pRXWN5Hf228e48KdPb5R/7KQq/viP++i9bQ0Ag7ZfzV1//QOX3/AYl9/wGGd858VSVLesqL6wlMJhwOyI+FcTZY4Cbo2ImoiYA1QB+7b0OxQt+Em6XtJiSS8X6xrl5POT/sW8uT03bB930hxefLYfk485iBef7cdxJ721UflvfOt1ZvxzQFtX0/J8/ri3mDe310Z5AwatYew+77L4ne4b5S+c35OzThrPWSeN58pL9mjLapanKDDBAEnT89LkLZxxInBL3vaZkl5K4kjfJG8IMC+vTHWS1yLFbPndAEwo4vnLRv9Ba9nnk+/y4D1DN+Tt/6nFPPyH3O/l4T8MYf/xiz/cN34R78zvwb9mb9PmdbWc/gPXsM8nFvHg/cM3yv/G2S/z26tGUwGvrhaVorAELImIcXlp6mbnkroAnwduT7KuBnYi1yVeCFzaULSRqrT4N1W04BcRjwPLinX+cjL53Nf57a92Juo//N306b+O5Uu6ArB8SVf69FsHQNdutXzhxDncPHWnktTVciaf0xDkPvyd7ffJd1j6bjfmVG27WfntB6/mst8+xsVX/IPd9ljallUtPwFEFJYK81nguYhYBBARiyKiLiLqgd/wYde2GhiWd9xQYEFLv0bJ7/lJmtzQJF5Xv6bU1Ultn4MW8/7yLlS9vvkfTGO+ctps7rl5BGvXeKypVPb5xDu8v7wrVbP6bMjr2rWW4094g99du+tm5Zct7cpJx36as782nmsv343vXDiD7j3Wb1YuS1r5nt8k8rq8kgbn7TsGaLh1dh8wUVJXSSOBUcAzLf0OJf8LTJrBUwG27TKo3XU2Ru/xHvsdvJhxB75Lly71dN+mlm9f9BLvLe1C3wE1LF/Slb4DanhvWRcAdh7zHgce9g5fP3sWPXvVEvWwrqYDf5j2kRJ/k+wYvfsy9vvkO4w7YFHud9azlnMveJ7tdljNFTc+BsCAgWv51fWP861vHMTyZd1Yub4jAFWz+rBwfk+GDF9F1et9SvclSqg1n/OT1AP4NHBqXvZPJY0l18ac27AvIl6RNA14FagFzmjpSC+UQfBr7268YmduvGJnAD6+9zKO/epcfvbD3fn6ObM4/HPzuf2GHTn8c/N56m+DAPjuKfttOPZLk6tYu6ajA18bu/Ga0dx4zWgAPr7nEo6dNJuffH+fjcpcf8dDfPPkg1nxfld696nhgxVdqK8X2++wih2GreKd+T1KUfXykK5L28ypYjXQf5O8rzZRfgowpTWu7eBXJLffMJLzLn6RTx81n3ff6cb/fNcjhO3VmLFL+cops6irFfX14spLdueDlV1KXa2SqoQ3PBRFGtaSdAswHhgALAIujIjrmjpm2y6D4hMDjy9KfaxIunUtdQ0shX9W/473a95pbNS0YL36DI09Dz6noLJP3P+fMyJi3NZcr1iK1vKLiEnFOreZlVYltPzc7TWzdAKoa//Rz8HPzFJzy8/MsqkCXoFx8DOz1NzyM7Ps8dKVZpZFAuQBDzPLIvmen5lljru9ZpZNrfdubyk5+JlZah7tNbNscsvPzDInPNprZlnV/mOfg5+ZpedHXcwsmxz8zCxzAki3IHlZcvAzs1REuNtrZhlV3/6bfiVft9fM2pmGbm8hqRmS5kqaKekFSdOTvH6SHpL0ZvKzb1758yVVSZol6Yit+RoOfmaWmiIKSgU6JCLG5i10dB7wSESMAh5JtpE0GpgI7AZMAK6S1LGl38HBz8zSa1i7t7nUMkcBNyafbwSOzsu/NSJqImIOUAXs29KLOPiZWUoFBr5c8BsgaXpemrz5yfiLpBl5+7aLiIUAyc9BSf4QYF7esdVJXot4wMPM0km3etuSZtbtPTAiFkgaBDwk6fUmyja23nCLm5du+ZlZaq11zy8iFiQ/FwN3k+vGLpI0GCD5uTgpXg0Myzt8KLCgpd/Bwc/M0muFe36Sekrq1fAZ+AzwMnAfcGJS7ETg3uTzfcBESV0ljQRGAc+09Cu422tm6QRQ3yoPOW8H3C0JcrHo5oh4QNKzwDRJJwNvA8cBRMQrkqYBrwK1wBkRUdfSizv4mVlKrTOTc0S8BezRSP5S4LAtHDMFmLLVF8fBz8xawq+3mVnmBFDX/l9vc/Azs5QCwsHPzLLI3V4zy5zWG+0tKQc/M0vPLT8zyyQHPzPLnAioa/GzxWXDwc/M0nPLz8wyycHPzLInPNprZhkUEH7I2cwyya+3mVnmRFTE0pUOfmaWngc8zCyLwi0/M8ue1pnMtNQc/MwsHU9sYGZZFED49TYzy5zwZKZmllHhbq+ZZVIFtPwUZTRqI+ld4F+lrkcRDACWlLoSlkql/s4+EhEDt+YEkh4g9+9TiCURMWFrrlcsZRX8KpWk6RExrtT1sML5d1b5OpS6AmZmpeDgZ2aZ5ODXNqaWugKWmn9nFc73/Mwsk9zyM7NMcvAzs0xy8CsiSRMkzZJUJem8UtfHmifpekmLJb1c6rpYcTn4FYmkjsCVwGeB0cAkSaNLWysrwA1AWT6Ua63Lwa949gWqIuKtiFgH3AocVeI6WTMi4nFgWanrYcXn4Fc8Q4B5edvVSZ6ZlQEHv+JRI3l+rsisTDj4FU81MCxveyiwoER1MbNNOPgVz7PAKEkjJXUBJgL3lbhOZpZw8CuSiKgFzgQeBF4DpkXEK6WtlTVH0i3Ak8AukqolnVzqOllx+PU2M8skt/zMLJMc/Mwskxz8zCyTHPzMLJMc/Mwskxz82hFJdZJekPSypNsl9diKc90g6QvJ52ubmnRB0nhJn2jBNeZK2myVry3lb1Lmg5TX+pGkb6eto2WXg1/7siYixkbEGGAdcFr+zmQmmdQi4pSIeLWJIuOB1MHPrJw5+LVfTwAfTVplj0q6GZgpqaOkSyQ9K+klSacCKOcKSa9K+iMwqOFEkh6TNC75PEHSc5JelPSIpBHkgux/JK3OgyQNlHRnco1nJR2YHNtf0l8kPS/p1zT+fvNGJN0jaYakVyRN3mTfpUldHpE0MMnbSdIDyTFPSNq1Vf41LXM6lboClp6kTuTmCXwgydoXGBMRc5IA8n5E7COpK/APSX8B9gR2AT4ObAe8Cly/yXkHAr8BDk7O1S8ilkm6BvggIn6WlLsZ+EVE/F3ScHJvsXwMuBD4e0T8WNK/ARsFsy34enKN7sCzku6MiKVAT+C5iDhX0gXJuc8kt7DQaRHxpqT9gKuAQ1vwz2gZ5+DXvnSX9ELy+QngOnLd0WciYk6S/xlg94b7ecC2wCjgYOCWiKgDFkj6ayPn3x94vOFcEbGlee0OB0ZLGxp2vSX1Sq5xbHLsHyUtL+A7nS3pmOTzsKSuS4F64LYk/3fAXZK2Sb7v7XnX7lrANcw24+DXvqyJiLH5GUkQWJWfBZwVEQ9uUu5Imp9SSwWUgdztkgMiYk0jdSn4fUlJ48kF0gMiYrWkx4BuWygeyXXf2/TfwKwlfM+v8jwInC6pM4CknSX1BB4HJib3BAcDhzRy7JPApySNTI7tl+SvBHrllfsLuS4oSbmxycfHgS8neZ8F+jZT122B5Ung25Vcy7NBB6Ch9folct3pFcAcSccl15CkPZq5hlmjHPwqz7Xk7uc9lyzC82tyLfy7gTeBmcDVwN82PTAi3iV3n+4uSS/yYbfzfuCYhgEP4GxgXDKg8iofjjr/F3CwpOfIdb/fbqauDwCdJL0EXAQ8lbdvFbCbpBnk7un9OMn/MnByUr9X8NIA1kKe1cXMMsktPzPLJAc/M8skBz8zyyQHPzPLJAc/M8skBz8zyyQHPzPLpP8DFPJY3LrFk+8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SGD_model = SGDClassifier(loss='log', max_iter=5000, penalty='l1')\n",
    "SGD_model.fit(X_train, y_train)\n",
    "grid_predictions = SGD_model.predict(X_test)\n",
    "ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, grid_predictions)).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aef235ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix is: \n",
      " [[2080  273]\n",
      " [ 404  445]]\n"
     ]
    }
   ],
   "source": [
    "print(\"confusion matrix is: \\n\", confusion_matrix(y_test,grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3dcead0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is:  0.7885696439725172 \n",
      "Precision is :  0.6197771587743732 \n",
      "Recall score is:  0.5241460541813898\n",
      "F1 Score:  0.47008547008547014\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score is: \" ,accuracy_score(grid_predictions, y_test), '\\nPrecision is : ',precision_score(y_test,grid_predictions),'\\nRecall score is: ' ,recall_score(y_test,grid_predictions))\n",
    "print(\"F1 Score: \", f1_score(y_test, SGD_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8d09a7",
   "metadata": {},
   "source": [
    "Grid search parameter tuning did not improve the initial model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32c87fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>relevent_experience</th>\n",
       "      <th>experience</th>\n",
       "      <th>company_size</th>\n",
       "      <th>last_new_job</th>\n",
       "      <th>training_hours</th>\n",
       "      <th>target</th>\n",
       "      <th>company_type_Early Stage Startup</th>\n",
       "      <th>company_type_Funded Startup</th>\n",
       "      <th>...</th>\n",
       "      <th>city_city_84</th>\n",
       "      <th>city_city_89</th>\n",
       "      <th>city_city_9</th>\n",
       "      <th>city_city_90</th>\n",
       "      <th>city_city_91</th>\n",
       "      <th>city_city_93</th>\n",
       "      <th>city_city_94</th>\n",
       "      <th>city_city_97</th>\n",
       "      <th>city_city_98</th>\n",
       "      <th>city_city_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.268051</td>\n",
       "      <td>0.942116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.104478</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.890497</td>\n",
       "      <td>0.654691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.137313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.346306</td>\n",
       "      <td>0.351297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.244776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.995836</td>\n",
       "      <td>0.680639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.152239</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019893</td>\n",
       "      <td>0.636727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.020896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   enrollee_id  city_development_index  relevent_experience  experience  \\\n",
       "0     0.268051                0.942116                  1.0    1.000000   \n",
       "1     0.890497                0.654691                  0.0    0.736842   \n",
       "2     0.346306                0.351297                  0.0    0.210526   \n",
       "3     0.995836                0.680639                  0.0    0.000000   \n",
       "4     0.019893                0.636727                  1.0    1.000000   \n",
       "\n",
       "   company_size  last_new_job  training_hours  target  \\\n",
       "0         0.000          0.25        0.104478     1.0   \n",
       "1         0.375          1.00        0.137313     0.0   \n",
       "2         0.000          0.00        0.244776     0.0   \n",
       "3         0.000          0.00        0.152239     1.0   \n",
       "4         0.375          1.00        0.020896     0.0   \n",
       "\n",
       "   company_type_Early Stage Startup  company_type_Funded Startup  ...  \\\n",
       "0                               0.0                          0.0  ...   \n",
       "1                               0.0                          0.0  ...   \n",
       "2                               0.0                          0.0  ...   \n",
       "3                               0.0                          0.0  ...   \n",
       "4                               0.0                          1.0  ...   \n",
       "\n",
       "   city_city_84  city_city_89  city_city_9  city_city_90  city_city_91  \\\n",
       "0           0.0           0.0          0.0           0.0           0.0   \n",
       "1           0.0           0.0          0.0           0.0           0.0   \n",
       "2           0.0           0.0          0.0           0.0           0.0   \n",
       "3           0.0           0.0          0.0           0.0           0.0   \n",
       "4           0.0           0.0          0.0           0.0           0.0   \n",
       "\n",
       "   city_city_93  city_city_94  city_city_97  city_city_98  city_city_99  \n",
       "0           0.0           0.0           0.0           0.0           0.0  \n",
       "1           0.0           0.0           0.0           0.0           0.0  \n",
       "2           0.0           0.0           0.0           0.0           0.0  \n",
       "3           0.0           0.0           0.0           0.0           0.0  \n",
       "4           0.0           0.0           0.0           0.0           0.0  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop education_level columns\n",
    "training_df = processed_data.drop('education_level',axis=1)\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b600a553",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(training_df.drop('target',axis=1), \n",
    "                                                    training_df['target'], test_size=0.20, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b78901f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(loss='log', max_iter=5000, penalty='l1')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD_model = SGDClassifier(loss='log', max_iter=5000, penalty='l1') #Using tuned parameteres\n",
    "SGD_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4fe5b44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix is: \n",
      " [[2217  136]\n",
      " [ 608  241]]\n"
     ]
    }
   ],
   "source": [
    "SGD_predictions = SGD_model.predict(X_test)\n",
    "print(\"confusion matrix is: \\n\", confusion_matrix(y_test,SGD_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "be257056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is:  0.7676452217364147\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score is: \" ,accuracy_score(SGD_predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68d5158e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is:  0.7676452217364147 \n",
      "Precision is :  0.6392572944297082 \n",
      "Recall score is:  0.2838633686690224\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Accuracy score is: \" ,accuracy_score(SGD_predictions, y_test), '\\nPrecision is : ',precision_score(y_test,SGD_predictions),'\\nRecall score is: ' ,recall_score(y_test,SGD_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "68fa681d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, SGD_predictions)).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21ab6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import SGDClassifier\n",
    "# SGD_model = SGDClassifier(loss='log', max_iter=5000, penalty='l1')\n",
    "# SGD_model.fit(X_train, y_train)\n",
    "# grid_predictions = SGD_model.predict(X_test)\n",
    "# f1 = f1_score(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
