{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47b5b929",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd85ac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a019a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing function\n",
    "def preprocessing_data(df: pd.DataFrame):\n",
    "    data = df.copy()\n",
    "    # drop NaN values for some columns\n",
    "    data = data.dropna(subset=['education_level','major_discipline', 'experience', 'last_new_job'])\n",
    "    # Replace other NaN with Unknown value \n",
    "    data = data.replace(np.nan,'Unknown')\n",
    "    # relevent_experience replace with 0 and 1, 1 for having experience and 0 for no experience\n",
    "    data['relevent_experience'] = data['relevent_experience'].replace(['Has relevent experience','No relevent experience'],[1,0])\n",
    "\n",
    "    # manually assign ordinal numbers to education_level and company_size\n",
    "    # for graduate level I will give 1 and for master 2 and for phd 3. Graduate level can be equals to masters and phd but usually people with phd would not represent themselves as graduate. \n",
    "    # any graduate level certificate can be considered as graduate so I will assign a lower number to graduate than masters. \n",
    "    # for company_size unknown will get 0.\n",
    "    \n",
    "    data['education_level'] = data['education_level'].replace(['Graduate','Masters','Phd'],[1,2,3])\n",
    "    data['company_size'] = data['company_size'].replace(['Unknown','<10', '10/49','50-99', '100-500','500-999','1000-4999','5000-9999','10000+'] ,range(0,9))\n",
    "\n",
    "    # convert experience and last_new_job to numeric values\n",
    "    data['experience'] = data['experience'].str.replace('>','').str.replace('<','')\n",
    "    data['experience'] = pd.to_numeric(data['experience'])\n",
    "\n",
    "    data['last_new_job'] = data['last_new_job'].str.replace('>','')\n",
    "    data['last_new_job'] = data['last_new_job'].replace('never',0)\n",
    "    data['last_new_job'] = pd.to_numeric(data['last_new_job'])\n",
    "\n",
    "    data = pd.get_dummies(data, columns = ['company_type', 'enrolled_university', 'gender', 'major_discipline','city'])\n",
    "    \n",
    "    #Normalize data using MinMaxScaler function of sci-kit leaern\n",
    "    x = data.values #returns a numpy array\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    data_scaled = pd.DataFrame(x_scaled, columns = data.columns)\n",
    "    return(data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed76e05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_selector(X, y,num_feats):\n",
    "    # Your code goes here (Multiple lines)\n",
    "    cor_list = []\n",
    "    \n",
    "    # create a list of all features\n",
    "    feature_name = X.columns.tolist()\n",
    "    \n",
    "    # Calculate the Pearson Correlation using corrcoef in numpy for each two features\n",
    "    for i in X.columns.tolist():\n",
    "        cor = np.corrcoef(X[i], y)[0, 1]\n",
    "        cor_list.append(cor)\n",
    "    \n",
    "    # replace Nan values with 0\n",
    "    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
    "    \n",
    "    # we use argsort to show the rank of each correlation in the list after sorting, and we select the last N number of features where N \n",
    "    # is the num_feats.\n",
    "    cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[-num_feats:]].columns.tolist()\n",
    "    \n",
    "    #indicate whether the faeture is selected or not\n",
    "    cor_support = [True if i in cor_feature else False for i in feature_name]\n",
    "    # Your code ends here\n",
    "    return cor_support, cor_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0fa15b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data =  pd.read_csv(\"aug_train.csv\")\n",
    "processed_data = preprocessing_data(raw_data)\n",
    "y = processed_data.target\n",
    "X = processed_data.drop(columns=['target','enrollee_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4be0dbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 selected features\n"
     ]
    }
   ],
   "source": [
    "cor_support, cor_feature = cor_selector(X, y,100)\n",
    "print(str(len(cor_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f38693e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eliminated_features = list(set(X.columns)-set(cor_feature)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "367310fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = processed_data.drop(columns = eliminated_features)\n",
    "y = selected_data.target\n",
    "X = selected_data.drop(columns=['target','enrollee_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8b5bff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split test-train data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092b0989",
   "metadata": {},
   "source": [
    "# 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50a18ec",
   "metadata": {},
   "source": [
    "# 2. Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8a869f",
   "metadata": {},
   "source": [
    "# 3. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2a4cad",
   "metadata": {},
   "source": [
    "# 4. SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654e8a11",
   "metadata": {},
   "source": [
    "# 5. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed0a246f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1 Score:  0.5752045311516678\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC(C= 1, gamma= 0.1, kernel= 'rbf', random_state=42) \n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "f1 = f1_score(y_test,y_pred)\n",
    "print(\"\\nF1 Score: \", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd90d96",
   "metadata": {},
   "source": [
    "## SVM with weighted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "599f46b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1 Score:  0.641298833079655\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC(C= 1, gamma= 0.1, kernel= 'rbf',class_weight={1: 3}, random_state=42) \n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "f1 = f1_score(y_test,y_pred)\n",
    "print(\"\\nF1 Score: \", f1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3.9",
   "language": "python",
   "name": "venv3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
